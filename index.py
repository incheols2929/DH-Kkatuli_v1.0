from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import StreamingResponse, HTMLResponse
from llama_cpp import Llama
import json
import asyncio
import logging
import os
import psutil
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

# ëª¨ë¸ì„ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸í•˜ë˜ ì´ˆê¸°í™”ëŠ” ì§€ì—°
llm = None


def optimize_system():
    """ì‹œìŠ¤í…œ ìµœì í™” ì„¤ì •"""
    # CPU ì¹œí™”ë„ ì„¤ì • (ëª¨ë“  ì½”ì–´ ì‚¬ìš©)
    try:
        process = psutil.Process()
        process.cpu_affinity(list(range(psutil.cpu_count())))
        # ìš°ì„ ìˆœìœ„ ë†’ìŒìœ¼ë¡œ ì„¤ì •
        process.nice(psutil.HIGH_PRIORITY_CLASS)
    except:
        pass


def initialize_model():
    """ëª¨ë¸ì„ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”"""
    global llm
    if llm is None:
        try:
            logger.info("ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            llm = Llama(
                model_path="model/EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf",
                # model_path="model/Gugugo-koen-7B-V1.1.Q8_0.gguf",
                # model_path="model/KONI-Llama3-8B-20240630.Q4_0.gguf",
                # model_path="model/llama-3.2-Korean-Bllossom-3B-Q4_K_M.gguf",
                n_ctx=4096,  # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¦ê°€
                n_threads=8,
                n_threads_batch=8,
                n_gpu_layers=0,
                verbose=False,
                n_batch=1024,  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
                use_mlock=False,
                use_mmap=True,
                main_gpu=0,
                numa=False,
                # ì¶”ê°€ ì„±ëŠ¥ ìµœì í™” ì˜µì…˜
                seed=-1,  # ëœë¤ ì‹œë“œ
                flash_attn=True,  # Flash Attention í™œì„±í™” (ì§€ì›ë˜ëŠ” ê²½ìš°)
            )
            logger.info("ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise e


def create_optimized_prompt(message: str) -> str:
    """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    # ë©”ì‹œì§€ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
    if any(keyword in message.lower() for keyword in ['ì½”ë“œ', 'code', 'í”„ë¡œê·¸ë˜ë°', 'íŒŒì´ì¬', 'ìë°”']):
        return f"""<|system|>ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í”„ë¡œê·¸ë˜ë°ê³¼ ê¸°ìˆ  ë¬¸ì œì— ëŒ€í•´ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.</s>
<|user|>{message}</s>
<|assistant|>"""
    elif any(keyword in message.lower() for keyword in ['ì„¤ëª…', 'ì•Œë ¤ì¤˜', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ìˆœìœ„', 'ì •ë³´']):
        return f"""<|system|>ë‹¹ì‹ ì€ ì§€ì‹ì´ í’ë¶€í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìì„¸í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤. ì¶©ë¶„í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”.</s>
<|user|>{message}</s>
<|assistant|>"""
    else:
        return f"""<|system|>ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì„±ì˜ê» ë‹µë³€í•´ì£¼ì„¸ìš”.</s>
<|user|>{message}</s>
<|assistant|>"""


def is_response_complete(text: str, token_count: int) -> bool:
    """ì‘ë‹µì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸ - ë” ê´€ëŒ€í•œ ì¡°ê±´ìœ¼ë¡œ ë³€ê²½"""
    # ìµœì†Œ í† í° ìˆ˜ í™•ì¸ (ë„ˆë¬´ ì§§ì€ ë‹µë³€ ë°©ì§€)
    if token_count < 30:  # ìµœì†Œ 30í† í°ì€ ìƒì„±í•˜ë„ë¡
        return False

    # í…ìŠ¤íŠ¸ ê¸¸ì´ë„ í™•ì¸ (í•œêµ­ì–´ íŠ¹ì„±ìƒ)
    if len(text.strip()) < 50:  # ìµœì†Œ 50ìëŠ” ìƒì„±í•˜ë„ë¡
        return False

    # ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸ (ë” ì—„ê²©í•œ íŒ¨í„´)
    complete_patterns = [
        r'.+[.!?]\s*$',  # ë‚´ìš©ì´ ìˆê³  ë¬¸ì¥ë¶€í˜¸ë¡œ ëë‚¨
        r'.+ì…ë‹ˆë‹¤\.$',  # ë‚´ìš©ì´ ìˆê³  "ì…ë‹ˆë‹¤."ë¡œ ëë‚¨
        r'.+ìŠµë‹ˆë‹¤\.$',  # ë‚´ìš©ì´ ìˆê³  "ìŠµë‹ˆë‹¤."ë¡œ ëë‚¨
        r'.+ë©ë‹ˆë‹¤\.$',  # ë‚´ìš©ì´ ìˆê³  "ë©ë‹ˆë‹¤."ë¡œ ëë‚¨
        r'.+ìˆìŠµë‹ˆë‹¤\.$',  # ë‚´ìš©ì´ ìˆê³  "ìˆìŠµë‹ˆë‹¤."ë¡œ ëë‚¨
        r'.+í•©ë‹ˆë‹¤\.$',  # ë‚´ìš©ì´ ìˆê³  "í•©ë‹ˆë‹¤."ë¡œ ëë‚¨
    ]

    # ì—¬ëŸ¬ ë¬¸ì¥ì´ í¬í•¨ë˜ì–´ ìˆê³  ë§ˆì§€ë§‰ì´ ì™„ì „í•œ ì¢…ë£Œì¸ì§€ í™•ì¸
    sentences = re.split(r'[.!?]', text.strip())
    if len(sentences) >= 2:  # ìµœì†Œ 2ê°œ ë¬¸ì¥ì´ ìˆì„ ë•Œë§Œ ì¢…ë£Œ ê³ ë ¤
        return any(re.search(pattern, text.strip()) for pattern in complete_patterns)

    return False


def should_stop_generation(accumulated_text: str, current_token: str, token_count: int) -> bool:
    """ìƒì„±ì„ ì¤‘ë‹¨í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨ - ë” ê´€ëŒ€í•˜ê²Œ ìˆ˜ì •"""
    # ë°˜ë³µ íŒ¨í„´ ê°ì§€ (ë” ì—„ê²©í•˜ê²Œ)
    if token_count > 50:  # 50í† í° ì´í›„ì—ë§Œ ë°˜ë³µ ê²€ì‚¬
        words = accumulated_text.split()
        if len(words) >= 15:  # 15ê°œ ë‹¨ì–´ ì´ìƒì¼ ë•Œë§Œ ê²€ì‚¬
            # ìµœê·¼ 7ê°œ ë‹¨ì–´ê°€ ë°˜ë³µë˜ëŠ”ì§€ í™•ì¸ (ë” ê¸´ íŒ¨í„´)
            recent_words = words[-7:]
            previous_words = words[-14:-7] if len(words) >= 14 else []
            if recent_words == previous_words and len(set(recent_words)) > 2:
                logger.info(f"ë°˜ë³µ íŒ¨í„´ ê°ì§€: {recent_words}")
                return True

    # ë¶€ì ì ˆí•œ íŒ¨í„´ ê°ì§€
    unwanted_patterns = [
        "ì§ˆë¬¸:",
        "ë‹µë³€:",
        "<|user|>",
        "<|assistant|>",
        "<|system|>",
        "Human:",
        "AI:",
        "\n\nì§ˆë¬¸",
        "\n\në‹µë³€",
        "ì‚¬ìš©ì:",
        "\nì‚¬ìš©ì:"
    ]

    for pattern in unwanted_patterns:
        if pattern in current_token or pattern in accumulated_text[-100:]:  # ë§ˆì§€ë§‰ 100ìì—ì„œ ê²€ì‚¬
            logger.info(f"ë¶€ì ì ˆí•œ íŒ¨í„´ ê°ì§€: {pattern}")
            return True

    return False


@app.post("/chat")
async def chat_endpoint(request: Request):
    try:
        # ëª¨ë¸ ì´ˆê¸°í™” í™•ì¸
        if llm is None:
            optimize_system()
            initialize_model()

        data = await request.json()
        user_message = data.get("message", "").strip()

        if not user_message:
            raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        logger.info(f"ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}")

        # ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt = create_optimized_prompt(user_message)

        def generate():
            try:
                logger.info(f"í”„ë¡¬í”„íŠ¸: {prompt[:100]}...")  # í”„ë¡¬í”„íŠ¸ ì¼ë¶€ë§Œ ë¡œê¹…

                response = llm(
                    prompt,
                    max_tokens=2048,  # í† í° ìˆ˜ ì¦ê°€
                    temperature=0.7,  # ì ì ˆí•œ ì°½ì˜ì„±
                    top_p=0.9,  # í† í° ì„ íƒ ë²”ìœ„
                    top_k=40,  # ìƒìœ„ Kê°œ í† í°ë§Œ ê³ ë ¤
                    repeat_penalty=1.15,  # ë°˜ë³µ í˜ë„í‹°
                    frequency_penalty=0.2,  # ë¹ˆë„ í˜ë„í‹°
                    presence_penalty=0.1,  # ì¡´ì¬ í˜ë„í‹°
                    echo=False,
                    stream=True,
                    stop=["</s>", "<|user|>", "<|system|>", "Human:", "\nì§ˆë¬¸:", "\n\n"]  # ì¼ë¶€ stop ì¡°ê±´ ì™„í™”
                )

                token_count = 0
                accumulated_text = ""

                for chunk in response:
                    if 'choices' in chunk and len(chunk['choices']) > 0:
                        text = chunk['choices'][0].get('text', '')
                        if text:
                            accumulated_text += text

                            # ì¤‘ë‹¨ ì¡°ê±´ ê²€ì‚¬
                            if should_stop_generation(accumulated_text, text, token_count):
                                logger.info("ë¶€ì ì ˆí•œ íŒ¨í„´ ê°ì§€, ìƒì„± ì¤‘ë‹¨")
                                break

                            token_count += 1

                            # ë””ë²„ê¹… ë¡œê·¸ ë ˆë²¨ ì¡°ì •
                            if token_count % 20 == 0:  # 20í† í°ë§ˆë‹¤ ë¡œê¹…
                                logger.info(f"í† í° #{token_count}: ìƒì„± ì§„í–‰ ì¤‘... (ê¸¸ì´: {len(accumulated_text)})")

                            yield f"data: {json.dumps({'text': text}, ensure_ascii=False)}\n\n"

                            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì™„ë£Œ ì²´í¬ - ë” ê´€ëŒ€í•œ ì¡°ê±´
                            if text in '.!?' and is_response_complete(accumulated_text, token_count):
                                logger.info(f"ë¬¸ì¥ ì™„ë£Œ ê°ì§€, ìƒì„± ì¢…ë£Œ (í† í°: {token_count}, ê¸¸ì´: {len(accumulated_text)})")
                                break

                            # ìµœëŒ€ í† í° ìˆ˜ ì œí•œ
                            if token_count > 1500:
                                logger.info("ìµœëŒ€ í† í° ìˆ˜ ë„ë‹¬, ìƒì„± ì¤‘ë‹¨")
                                break

                logger.info(f"ì´ ìƒì„±ëœ í† í° ìˆ˜: {token_count}")
                logger.info(f"ìƒì„±ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(accumulated_text)}")
                yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                error_msg = json.dumps({'error': f'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}, ensure_ascii=False)
                yield f"data: {error_msg}\n\n"

        return StreamingResponse(generate(), media_type="text/event-stream")

    except Exception as e:
        logger.error(f"ì±— ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/")
async def get_chat_interface():
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>DH-Kkatuli_v1.0 (Enhanced)</title>
        <meta charset="UTF-8">
        <style>
            #chat-container { 
                max-width: 900px; 
                margin: 20px auto; 
                padding: 20px;
                font-family: 'Malgun Gothic', Arial, sans-serif;
            }
            #messages { 
                margin-bottom: 20px;
                padding: 15px;
                height: 500px;
                overflow-y: auto;
                border: 1px solid #ddd;
                border-radius: 8px;
                background-color: #fafafa;
            }
            .message { 
                margin: 15px 0;
                padding: 12px 15px;
                border-radius: 8px;
                word-wrap: break-word;
                line-height: 1.5;
            }
            .user { 
                background-color: #e3f2fd;
                margin-left: 15%;
                text-align: right;
                border-left: 4px solid #2196f3;
            }
            .assistant { 
                background-color: #f8f9fa;
                margin-right: 15%;
                border-left: 4px solid #28a745;
            }
            #input-container {
                display: flex;
                gap: 10px;
                margin-top: 15px;
            }
            #user-input {
                flex-grow: 1;
                padding: 12px;
                border: 2px solid #ddd;
                border-radius: 6px;
                font-size: 14px;
                transition: border-color 0.3s;
            }
            #user-input:focus {
                border-color: #2196f3;
                outline: none;
            }
            button {
                padding: 12px 24px;
                background-color: #2196f3;
                color: white;
                border: none;
                border-radius: 6px;
                cursor: pointer;
                font-size: 14px;
                transition: background-color 0.3s;
            }
            button:hover {
                background-color: #1976d2;
            }
            button:disabled {
                background-color: #ccc;
                cursor: not-allowed;
            }
            #stop-btn {
                background-color: #f44336;
                display: none;
            }
            #stop-btn:hover {
                background-color: #d32f2f;
            }
            .loading {
                color: #666;
                font-style: italic;
                animation: pulse 1.5s infinite;
            }
            @keyframes pulse {
                0% { opacity: 1; }
                50% { opacity: 0.5; }
                100% { opacity: 1; }
            }
            .stopped {
                color: #666;
                font-style: italic;
                border-left: 4px solid #f44336;
            }
            .error {
                background-color: #ffebee;
                border-left: 4px solid #f44336;
                color: #c62828;
            }
            .stats {
                font-size: 12px;
                color: #666;
                margin-top: 10px;
                text-align: center;
            }
        </style>
    </head>
    <body>
        <div id="chat-container">
            <h1>ğŸ¤– DH-Kkatuli_v1.0 (Enhanced)</h1>
            <div class="stats">
                <span>ëª¨ë¸: EEVE-Korean-Instruct-10.8B | ìµœì í™”ëœ ë‹µë³€ ìƒì„±</span>
            </div>
            <div id="messages"></div>
            <div id="input-container">
                <input type="text" id="user-input" placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (Enterë¡œ ì „ì†¡)">
                <button id="send-btn" onclick="sendMessage()">ğŸ’¬ ì „ì†¡</button>
                <button id="stop-btn" onclick="stopGeneration()">â¹ï¸ ì¤‘ë‹¨</button>
            </div>
        </div>

        <script>
            let currentController = null;
            let isGenerating = false;
            let messageCount = 0;

            function addMessage(role, content, isLoading = false) {
                const messagesDiv = document.getElementById('messages');
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${role}${isLoading ? ' loading' : ''}`;
                messageDiv.textContent = content;
                messagesDiv.appendChild(messageDiv);
                messagesDiv.scrollTop = messagesDiv.scrollHeight;
                messageCount++;
                return messageDiv;
            }

            function updateButtonStates(generating) {
                const sendBtn = document.getElementById('send-btn');
                const stopBtn = document.getElementById('stop-btn');
                const userInput = document.getElementById('user-input');

                isGenerating = generating;
                sendBtn.disabled = generating;
                userInput.disabled = generating;

                if (generating) {
                    stopBtn.style.display = 'inline-block';
                    sendBtn.style.display = 'none';
                } else {
                    stopBtn.style.display = 'none';
                    sendBtn.style.display = 'inline-block';
                }
            }

            function stopGeneration() {
                if (currentController) {
                    currentController.abort();
                    currentController = null;
                }
                updateButtonStates(false);

                const messages = document.querySelectorAll('.message.assistant');
                if (messages.length > 0) {
                    const lastMessage = messages[messages.length - 1];
                    if (!lastMessage.textContent.includes('[ì¤‘ë‹¨ë¨]')) {
                        lastMessage.textContent += ' [ì¤‘ë‹¨ë¨]';
                        lastMessage.classList.add('stopped');
                    }
                }
            }

            async function sendMessage() {
                const input = document.getElementById('user-input');
                const message = input.value.trim();

                if (!message || isGenerating) return;

                input.value = '';
                updateButtonStates(true);
                addMessage('user', message);
                const loadingMsg = addMessage('assistant', 'ğŸ¤” ìƒê°í•˜ëŠ” ì¤‘...', true);

                currentController = new AbortController();
                const startTime = Date.now();

                try {
                    const response = await fetch('/chat', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ message: message }),
                        signal: currentController.signal
                    });

                    if (!response.ok) {
                        throw new Error(`ì„œë²„ ì˜¤ë¥˜: ${response.status}`);
                    }

                    const reader = response.body.getReader();
                    const decoder = new TextDecoder();
                    let assistantResponse = '';

                    loadingMsg.remove();
                    const responseDiv = addMessage('assistant', '');

                    try {
                        while (true) {
                            const { value, done } = await reader.read();
                            if (done) break;

                            const chunk = decoder.decode(value);
                            const lines = chunk.split('\\n');

                            for (const line of lines) {
                                if (line.startsWith('data: ')) {
                                    const data = line.slice(6);
                                    if (data === '[DONE]') {
                                        const duration = ((Date.now() - startTime) / 1000).toFixed(1);
                                        console.log(`ì‘ë‹µ ì™„ë£Œ (${duration}ì´ˆ)`);
                                        break;
                                    }

                                    try {
                                        const parsed = JSON.parse(data);
                                        if (parsed.text) {
                                            assistantResponse += parsed.text;
                                            responseDiv.textContent = assistantResponse;
                                            responseDiv.scrollIntoView({ behavior: 'smooth', block: 'end' });
                                        } else if (parsed.error) {
                                            responseDiv.textContent = `âŒ ${parsed.error}`;
                                            responseDiv.className += ' error';
                                            break;
                                        }
                                    } catch (e) {
                                        console.error('JSON íŒŒì‹± ì˜¤ë¥˜:', e);
                                    }
                                }
                            }
                        }
                    } catch (readError) {
                        if (readError.name === 'AbortError') {
                            console.log('ìŠ¤íŠ¸ë¦¼ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨');
                        } else {
                            throw readError;
                        }
                    }

                    if (!assistantResponse.trim() && !responseDiv.classList.contains('stopped')) {
                        responseDiv.textContent = 'âŒ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
                        responseDiv.className += ' error';
                    }

                } catch (error) {
                    if (error.name === 'AbortError') {
                        console.log('ìš”ì²­ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨');
                        if (loadingMsg.parentNode) {
                            loadingMsg.textContent = 'â¹ï¸ ìš”ì²­ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.';
                            loadingMsg.className = 'message assistant stopped';
                        }
                    } else {
                        console.error('ì˜¤ë¥˜:', error);
                        if (loadingMsg.parentNode) {
                            loadingMsg.textContent = `âŒ ì˜¤ë¥˜: ${error.message}`;
                            loadingMsg.className = 'message assistant error';
                        }
                    }
                } finally {
                    updateButtonStates(false);
                    currentController = null;
                }
            }

            // ì—”í„° í‚¤ ì´ë²¤íŠ¸
            document.getElementById('user-input').addEventListener('keypress', function(e) {
                if (e.key === 'Enter' && !e.shiftKey && !isGenerating) {
                    e.preventDefault();
                    sendMessage();
                }
            });

            // í˜ì´ì§€ ì–¸ë¡œë“œ ì‹œ ì •ë¦¬
            window.addEventListener('beforeunload', function() {
                if (currentController) {
                    currentController.abort();
                }
            });

            // ì´ˆê¸° í¬ì»¤ìŠ¤
            document.getElementById('user-input').focus();
        </script>
    </body>
    </html>
    """
    return HTMLResponse(content=html_content, status_code=200)


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="192.168.0.13", port=8000)